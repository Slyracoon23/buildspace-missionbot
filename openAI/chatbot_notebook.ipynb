{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BsHLvatMMBp"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "EEuRe-IZGfcO"
      },
      "outputs": [],
      "source": [
        "\n",
        "# !pip install -q openai\n",
        "# !pip install -q gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unIGGtl_MO4u"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "dOxJoWGvLFne"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import gradio as gr\n",
        "import itertools\n",
        "import os\n",
        "import requests\n",
        "from urllib.parse import urlsplit, parse_qs"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XRwvS_F2MYCZ"
      },
      "source": [
        "# API Key \n",
        "\n",
        "openai.api_key = Replace this with your API key: https://beta.openai.com/docs/quickstart/add-your-api-key\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "ev3uSJn_MUdv"
      },
      "outputs": [],
      "source": [
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\") # Replace this with your API key: https://beta.openai.com/docs/quickstart/add-your-api-key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfpMV1W7MdBW"
      },
      "source": [
        "# OpenAI Chat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "h8EY5yomJDC_"
      },
      "outputs": [],
      "source": [
        "def openai_chat(prompt, history):\n",
        "    start_sequence = \"\\nAI:\"\n",
        "    restart_sequence = \"\\nHuman: \"\n",
        "    prompt_engineering = \"\"\"The following is a conversation with an AI assistant. The assistant is helpful, creative, clever, and very friendly. The AI assistant goal is to help the user find a mission statement that best aligns their beliefs in the DAO.  The DAO is called CityDAO wants to build the citys of the future.\\n\n",
        "    AI: I am an AI created by OpenAI. How can I help you define your mission statement?\n",
        "    \"\"\"\n",
        "\n",
        "    history = [ (human_prompt.replace(\"<p>\", \"Human:\").replace(\"</p>\", \"\\n\"), ai_prompt.replace(\"<p>\", \"AI:\").replace(\"</p>\", \"\\n\" )) for human_prompt, ai_prompt in history]\n",
        "\n",
        "    flat_history = list(itertools.chain(*history))\n",
        "\n",
        "\n",
        "    prompt_history = prompt_engineering + ''.join(flat_history)\n",
        "\n",
        "    \n",
        "\n",
        "    prompt = prompt_history + (\"Human: \" + prompt + \"\\n\")\n",
        "\n",
        "    print(\"prompt:\", repr(prompt))\n",
        "    completions = openai.Completion.create(\n",
        "        engine=\"text-davinci-003\",\n",
        "        prompt=prompt,\n",
        "        temperature=0.9,\n",
        "        max_tokens=150,\n",
        "        top_p=1,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0.6,\n",
        "        stop=[\" Human:\", \" AI:\"]\n",
        "    )\n",
        "\n",
        "    message = completions.choices[0].text\n",
        "    return message.strip()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AWS ZK Lambda Endpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a Request Function that will submit id, identity, and message to the API\n",
        "def createZKP_request(id, identity,group, attestation):\n",
        "    # Create a dictionary of the parameters\n",
        "    params = {\n",
        "        \"id\": id,\n",
        "        \"identity\": identity,\n",
        "        \"group\": group,\n",
        "        \"attestation\": attestation,\n",
        "    }\n",
        "    # Make a POST request to the API\n",
        "    response = requests.post(\"https://api.openai.com/v1/engines/davinci/completions\", params=params)\n",
        "    return response.json()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8j5l3L1MgTo"
      },
      "source": [
        "# Gradio Interface Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "njt_0emtJDJp"
      },
      "outputs": [],
      "source": [
        "def chatbot(input, history=[]):\n",
        "    output = openai_chat(input, history)\n",
        "    history.append((input, output))\n",
        "    return history, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "NhJlnlyuQofl"
      },
      "outputs": [],
      "source": [
        "def echo(input, history = []):\n",
        "  history.append((input, \"Hello World\"))\n",
        "  return history, history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIr6DORaMjWf"
      },
      "source": [
        "# Launch Interface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "id": "XuUV25fQGB0I",
        "outputId": "2256dba0-c20b-4a6e-cd92-87a11c3688cf"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "id": "u54uD3Z8Ig-6",
        "outputId": "5d535e5e-bd0e-46a3-ff91-4dd4079a5eea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on local URL:  http://127.0.0.1:7863\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prompt: 'The following is a conversation with an AI assistant. The assistant is helpful, creative, clever, and very friendly. The AI assistant goal is to help the user find a mission statement that best aligns their beliefs in the DAO.  The DAO is called CityDAO wants to build the citys of the future.\\n\\n    AI: I am an AI created by OpenAI. How can I help you define your mission statement?\\n    Human: Can you help me?\\n'\n",
            "Request headers dictionary: Headers({'host': '127.0.0.1:7863', 'user-agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:107.0) Gecko/20100101 Firefox/107.0', 'accept': '*/*', 'accept-language': 'en-US,en;q=0.5', 'accept-encoding': 'gzip, deflate, br', 'referer': 'http://127.0.0.1:7863/', 'content-type': 'application/json', 'content-length': '76', 'origin': 'http://127.0.0.1:7863', 'connection': 'keep-alive', 'sec-fetch-dest': 'empty', 'sec-fetch-mode': 'cors', 'sec-fetch-site': 'same-origin', 'sec-gpc': '1'})\n",
            "Params: {}\n"
          ]
        }
      ],
      "source": [
        "# Gradio Interface using gradio blocks \n",
        "# Retrive Gradio URL parameter from the URL\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "\n",
        "  history = gr.State([])\n",
        "  \n",
        "  with gr.Column(visible=True) as inital_column:\n",
        "    gr.Markdown(\n",
        "      \"\"\"\n",
        "      # Fellow Community Member!\n",
        "      I am missionBot! I am here to know your mission. Please start in the chat so I can get a sense of your mission, \n",
        "      and when you are done just submit your mission!\n",
        "      \"\"\")\n",
        "    outputDialogue = gr.Chatbot( )\n",
        "    inputText = gr.Textbox()\n",
        "\n",
        "    greet_btn = gr.Button(value=\"Submit my Mission\", visible=False)\n",
        "  \n",
        "  with gr.Column(visible=False) as final_column:\n",
        "  \n",
        "    gr.Markdown(\n",
        "      \"\"\"\n",
        "      Thank you for your mission! Your mission has been sent to the DAO for review.\n",
        "      \"\"\"\n",
        "    )\n",
        "    \n",
        "  def btn_click(input, history, request: gr.Request):\n",
        "    print(\"Request headers dictionary:\", request.headers)\n",
        "    referrer = request.headers.get(\"Referer\")\n",
        "    query = urlsplit(referrer).query\n",
        "    params = parse_qs(query)\n",
        "    print(\"Params:\", params)\n",
        "    # if params id exists enter if statement\n",
        "    # if \"id\" in params:\n",
        "    #     createZKP_request(params[\"id\"], \"None\", \"None\", str(history))\n",
        "    \n",
        "    # Update the state and rerender the interface\n",
        "    return {\n",
        "           inital_column: gr.update(visible=False),\n",
        "            final_column: gr.update(visible=True),\n",
        "        } \n",
        "  \n",
        "  \n",
        "  inputText.submit(fn=chatbot, inputs=[inputText, history], outputs=[outputDialogue, history])\n",
        "\n",
        "  greet_btn.click(fn=btn_click, inputs=[inputText,history], outputs=[inital_column, final_column])\n",
        "  outputDialogue.change(fn=lambda value: gr.update(visible=True) , inputs=outputDialogue, outputs=greet_btn)\n",
        "\n",
        "\n",
        "demo.launch(debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHk9kFWSN7bO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "gradio",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "02ef9d8203738d9aa09369cb338c7a899e17a6a93cd7f3d1c0b9855d9a530640"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
