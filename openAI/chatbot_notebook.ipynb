{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BsHLvatMMBp"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "EEuRe-IZGfcO"
      },
      "outputs": [],
      "source": [
        "\n",
        "# !pip install -q openai\n",
        "# !pip install -q gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unIGGtl_MO4u"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "dOxJoWGvLFne"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import gradio as gr\n",
        "import itertools\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRwvS_F2MYCZ"
      },
      "source": [
        "# API Key\n",
        "\n",
        "openai.api_key = Replace this with your API key: https://beta.openai.com/docs/quickstart/add-your-api-key\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "ev3uSJn_MUdv"
      },
      "outputs": [],
      "source": [
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\") # Replace this with your API key: https://beta.openai.com/docs/quickstart/add-your-api-key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfpMV1W7MdBW"
      },
      "source": [
        "# OpenAI Chat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "h8EY5yomJDC_"
      },
      "outputs": [],
      "source": [
        "def openai_chat(prompt, history):\n",
        "    start_sequence = \"\\nAI:\"\n",
        "    restart_sequence = \"\\nHuman: \"\n",
        "    prompt_engineering = \"\"\"The following is a conversation with an AI assistant. The assistant is helpful, creative, clever, and very friendly. The AI assistant goal is to help the user find a mission statement that best aligns their beliefs in the DAO.  The DAO is called CityDAO wants to build the citys of the future.\\n\n",
        "    AI: I am an AI created by OpenAI. How can I help you define your mission statement?\n",
        "    \"\"\"\n",
        "\n",
        "    history = [ (human_prompt.replace(\"<p>\", \"Human:\").replace(\"</p>\", \"\\n\"), ai_prompt.replace(\"<p>\", \"AI:\").replace(\"</p>\", \"\\n\" )) for human_prompt, ai_prompt in history]\n",
        "\n",
        "    flat_history = list(itertools.chain(*history))\n",
        "\n",
        "\n",
        "    prompt_history = prompt_engineering + ''.join(flat_history)\n",
        "\n",
        "    \n",
        "\n",
        "    prompt = prompt_history + (\"Human: \" + prompt + \"\\n\")\n",
        "\n",
        "    print(\"prompt:\", repr(prompt))\n",
        "    completions = openai.Completion.create(\n",
        "        engine=\"text-davinci-003\",\n",
        "        prompt=prompt,\n",
        "        temperature=0.9,\n",
        "        max_tokens=150,\n",
        "        top_p=1,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0.6,\n",
        "        stop=[\" Human:\", \" AI:\"]\n",
        "    )\n",
        "\n",
        "    message = completions.choices[0].text\n",
        "    return message.strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8j5l3L1MgTo"
      },
      "source": [
        "# Gradio Interface Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "njt_0emtJDJp"
      },
      "outputs": [],
      "source": [
        "def chatbot(input, history=[]):\n",
        "    output = openai_chat(input, history)\n",
        "    history.append((input, output))\n",
        "    return history, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "NhJlnlyuQofl"
      },
      "outputs": [],
      "source": [
        "def echo(input, history = []):\n",
        "  history.append((input, \"Hello World\"))\n",
        "  return history, history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIr6DORaMjWf"
      },
      "source": [
        "# Launch Interface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "id": "XuUV25fQGB0I",
        "outputId": "2256dba0-c20b-4a6e-cd92-87a11c3688cf"
      },
      "outputs": [],
      "source": [
        "# gr.Interface(fn = chatbot,\n",
        "#              inputs = [\"text\",'state'],\n",
        "#              outputs = [\"chatbot\",'state']).launch(debug = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "id": "u54uD3Z8Ig-6",
        "outputId": "5d535e5e-bd0e-46a3-ff91-4dd4079a5eea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on local URL:  http://127.0.0.1:7861\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prompt: 'The following is a conversation with an AI assistant. The assistant is helpful, creative, clever, and very friendly. The AI assistant goal is to help the user find a mission statement that best aligns their beliefs in the DAO.  The DAO is called CityDAO wants to build the citys of the future.\\n\\n    AI: I am an AI created by OpenAI. How can I help you define your mission statement?\\n    Human: Hi\\n'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/home/slyracoon23/miniconda3/envs/gradio/lib/python3.8/site-packages/gradio/routes.py\", line 321, in run_predict\n",
            "    output = await app.blocks.process_api(\n",
            "  File \"/home/slyracoon23/miniconda3/envs/gradio/lib/python3.8/site-packages/gradio/blocks.py\", line 1015, in process_api\n",
            "    result = await self.call_function(fn_index, inputs, iterator, request)\n",
            "  File \"/home/slyracoon23/miniconda3/envs/gradio/lib/python3.8/site-packages/gradio/blocks.py\", line 856, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/home/slyracoon23/miniconda3/envs/gradio/lib/python3.8/site-packages/anyio/to_thread.py\", line 31, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/home/slyracoon23/miniconda3/envs/gradio/lib/python3.8/site-packages/anyio/_backends/_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/home/slyracoon23/miniconda3/envs/gradio/lib/python3.8/site-packages/anyio/_backends/_asyncio.py\", line 867, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/tmp/ipykernel_930073/271625922.py\", line 2, in chatbot\n",
            "    output = openai_chat(input, history)\n",
            "  File \"/tmp/ipykernel_930073/4064709123.py\", line 20, in openai_chat\n",
            "    completions = openai.Completion.create(\n",
            "  File \"/home/slyracoon23/miniconda3/envs/gradio/lib/python3.8/site-packages/openai/api_resources/completion.py\", line 25, in create\n",
            "    return super().create(*args, **kwargs)\n",
            "  File \"/home/slyracoon23/miniconda3/envs/gradio/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 107, in create\n",
            "    requestor = api_requestor.APIRequestor(\n",
            "  File \"/home/slyracoon23/miniconda3/envs/gradio/lib/python3.8/site-packages/openai/api_requestor.py\", line 85, in __init__\n",
            "    self.api_key = key or util.default_api_key()\n",
            "  File \"/home/slyracoon23/miniconda3/envs/gradio/lib/python3.8/site-packages/openai/util.py\", line 186, in default_api_key\n",
            "    raise openai.error.AuthenticationError(\n",
            "openai.error.AuthenticationError: No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://onboard.openai.com for details, or email support@openai.com if you have any questions.\n"
          ]
        }
      ],
      "source": [
        "# Gradio Interface using gradio blocks\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "  gr.Markdown(\n",
        "  \"\"\"\n",
        "  # Fellow Community Member!\n",
        "  I am missionBot! I am here to know your mission. Please start in the chat so I can get a sense of your mission, \n",
        "  and when you are done just submit your mission!\n",
        "  \"\"\")\n",
        "  history = gr.State([])\n",
        "  outputDialogue = gr.Chatbot( )\n",
        "  inputText = gr.Textbox()\n",
        "\n",
        "  inputText.submit(fn=chatbot, inputs=[inputText, history], outputs=[outputDialogue, history])\n",
        "  greet_btn = gr.Button(value=\"Submit my Mission\", visible=False)\n",
        "  \n",
        "\n",
        "  outputDialogue.change(fn=lambda value: gr.update(visible=True) , inputs=outputDialogue, outputs=greet_btn)\n",
        "\n",
        "\n",
        "demo.launch(debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHk9kFWSN7bO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "gradio",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "02ef9d8203738d9aa09369cb338c7a899e17a6a93cd7f3d1c0b9855d9a530640"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
