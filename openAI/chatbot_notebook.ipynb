{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BsHLvatMMBp"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "EEuRe-IZGfcO"
      },
      "outputs": [],
      "source": [
        "\n",
        "# !pip install -q openai\n",
        "# !pip install -q gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unIGGtl_MO4u"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "dOxJoWGvLFne"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import gradio as gr\n",
        "import itertools\n",
        "import os\n",
        "import requests\n",
        "from urllib.parse import urlsplit, parse_qs\n",
        "import random"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XRwvS_F2MYCZ"
      },
      "source": [
        "# API Key \n",
        "\n",
        "openai.api_key = Replace this with your API key: https://beta.openai.com/docs/quickstart/add-your-api-key\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "ev3uSJn_MUdv"
      },
      "outputs": [],
      "source": [
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\") # Replace this with your API key: https://beta.openai.com/docs/quickstart/add-your-api-key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfpMV1W7MdBW"
      },
      "source": [
        "# OpenAI Chat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "h8EY5yomJDC_"
      },
      "outputs": [],
      "source": [
        "def openai_chat(prompt, history):\n",
        "    start_sequence = \"\\nAI:\"\n",
        "    restart_sequence = \"\\nHuman: \"\n",
        "    prompt_engineering = \"\"\"The following is a conversation with an AI assistant. The assistant is helpful, creative, clever, and very friendly. The AI assistant goal is to help the user find a mission statement that best aligns their beliefs in the DAO.  The DAO is called CityDAO wants to build the citys of the future.\\n\n",
        "    AI: I am an AI created by OpenAI. How can I help you define your mission statement?\n",
        "    \"\"\"\n",
        "\n",
        "    history = [ (human_prompt.replace(\"<p>\", \"Human:\").replace(\"</p>\", \"\\n\"), ai_prompt.replace(\"<p>\", \"AI:\").replace(\"</p>\", \"\\n\" )) for human_prompt, ai_prompt in history]\n",
        "\n",
        "    flat_history = list(itertools.chain(*history))\n",
        "\n",
        "\n",
        "    prompt_history = prompt_engineering + ''.join(flat_history)\n",
        "\n",
        "    \n",
        "\n",
        "    prompt = prompt_history + (\"Human: \" + prompt + \"\\n\")\n",
        "\n",
        "    print(\"prompt:\", repr(prompt))\n",
        "    completions = openai.Completion.create(\n",
        "        engine=\"text-davinci-003\",\n",
        "        prompt=prompt,\n",
        "        temperature=0.9,\n",
        "        max_tokens=150,\n",
        "        top_p=1,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0.6,\n",
        "        stop=[\" Human:\", \" AI:\"]\n",
        "    )\n",
        "\n",
        "    message = completions.choices[0].text\n",
        "    return message.strip()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AWS ZK Lambda Endpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a Request Function that will submit id, identity, and message to the API\n",
        "def createZKP_request(id, identity,group, attestation):\n",
        "    # Create a dictionary of the parameters\n",
        "    data = {\n",
        "        \"id\": id,\n",
        "        \"identity\": identity,\n",
        "        \"group\": attestation,\n",
        "        \"attestation\": \"Missionbot\", # Atttesation must be a string of 32 bytes or less\n",
        "    }\n",
        "    # Make a POST request to the AP\n",
        "    response = requests.post(\"https://eczl8gqxk5.execute-api.eu-central-1.amazonaws.com/default/Semaphore-proof-function\", json=data)\n",
        "    return response.ok\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8j5l3L1MgTo"
      },
      "source": [
        "# Gradio Interface Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "njt_0emtJDJp"
      },
      "outputs": [],
      "source": [
        "def chatbot(input, history=[]):\n",
        "    output = openai_chat(input, history)\n",
        "    history.append((input, output))\n",
        "    return history, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "NhJlnlyuQofl"
      },
      "outputs": [],
      "source": [
        "def echo(input, history = []):\n",
        "  history.append((input, \"Hello World\"))\n",
        "  return history, history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIr6DORaMjWf"
      },
      "source": [
        "# Launch Interface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "id": "u54uD3Z8Ig-6",
        "outputId": "5d535e5e-bd0e-46a3-ff91-4dd4079a5eea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on local URL:  http://127.0.0.1:7861\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prompt: 'The following is a conversation with an AI assistant. The assistant is helpful, creative, clever, and very friendly. The AI assistant goal is to help the user find a mission statement that best aligns their beliefs in the DAO.  The DAO is called CityDAO wants to build the citys of the future.\\n\\n    AI: I am an AI created by OpenAI. How can I help you define your mission statement?\\n    Human: can you bring the heat!\\n'\n",
            "Request headers dictionary: Headers({'host': '127.0.0.1:7861', 'user-agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:107.0) Gecko/20100101 Firefox/107.0', 'accept': '*/*', 'accept-language': 'en-US,en;q=0.5', 'accept-encoding': 'gzip, deflate, br', 'referer': 'http://127.0.0.1:7861/', 'content-type': 'application/json', 'content-length': '83', 'origin': 'http://127.0.0.1:7861', 'connection': 'keep-alive', 'sec-fetch-dest': 'empty', 'sec-fetch-mode': 'cors', 'sec-fetch-site': 'same-origin', 'sec-gpc': '1'})\n",
            "Params: {}\n"
          ]
        }
      ],
      "source": [
        "# Gradio Interface using gradio blocks \n",
        "# Retrive Gradio URL parameter from the URL\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "\n",
        "  history = gr.State([])\n",
        "  \n",
        "  with gr.Column(visible=True) as inital_column:\n",
        "    gr.Markdown(\n",
        "      \"\"\"\n",
        "      # Fellow Community Member!\n",
        "      I am missionBot! I am here to know your mission. Please start in the chat so I can get a sense of your mission, \n",
        "      and when you are done just submit your mission!\n",
        "      \"\"\")\n",
        "    outputDialogue = gr.Chatbot( )\n",
        "    inputText = gr.Textbox()\n",
        "\n",
        "    greet_btn = gr.Button(value=\"Submit my Mission\", visible=False)\n",
        "  \n",
        "  with gr.Column(visible=False) as final_column:\n",
        "  \n",
        "    gr.Markdown(\n",
        "      \"\"\"\n",
        "      Thank you for your mission! Your mission has been sent to the DAO for review.\n",
        "      To start a new mission please refresh the page!\n",
        "      \"\"\"\n",
        "    )\n",
        "    markdownID = gr.Markdown()\n",
        "    \n",
        "    \n",
        "  def btn_click(input, history, request: gr.Request):\n",
        "    print(\"Request headers dictionary:\", request.headers)\n",
        "    referrer = request.headers.get(\"Referer\")\n",
        "    query = urlsplit(referrer).query\n",
        "    params = parse_qs(query)\n",
        "    print(\"Params:\", params)\n",
        "    # if params id exists enter if statement\n",
        "    if \"id\" in params:\n",
        "       response = createZKP_request(int(params[\"id\"]), \"None\", \"None\", str(history))\n",
        "       # Update the state and rerender the interface\n",
        "       return {\n",
        "                inital_column: gr.update(visible=False),\n",
        "                final_column: gr.update(visible=True),\n",
        "                markdownID: gr.update(value=f\"Your mission number is: {params['id']}\")\n",
        "            } \n",
        "    else:\n",
        "      random_id = random.randrange(1000,8100)\n",
        "      response = createZKP_request(int(random_id), \"None\", \"None\", str(history))\n",
        "\n",
        "      # Update the state and rerender the interface\n",
        "      return {\n",
        "              inital_column: gr.update(visible=False),\n",
        "              final_column: gr.update(visible=True),\n",
        "              markdownID: gr.update(value=f\"Your mission Number is: {random_id}\")\n",
        "          } \n",
        "  \n",
        "  \n",
        "  inputText.submit(fn=chatbot, inputs=[inputText, history], outputs=[outputDialogue, history])\n",
        "\n",
        "  greet_btn.click(fn=btn_click, inputs=[inputText,history], outputs=[inital_column, final_column, markdownID])\n",
        "  outputDialogue.change(fn=lambda value: gr.update(visible=True) , inputs=outputDialogue, outputs=greet_btn)\n",
        "\n",
        "\n",
        "demo.launch(debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHk9kFWSN7bO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "gradio",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "02ef9d8203738d9aa09369cb338c7a899e17a6a93cd7f3d1c0b9855d9a530640"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
